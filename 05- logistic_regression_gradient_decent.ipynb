{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# # Import \n",
    "# =============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# # Load Data:\n",
    "# =============================================================================\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "dataset = load_breast_cancer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# # Logistic regressor class:\n",
    "# =============================================================================\n",
    "class Logistic_Regression_DIY(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    # Intiation Method\n",
    "    def __init__(self, learning_rate = 5e-5, num_step = 50000, intercept = False):\n",
    "        self.step = num_step\n",
    "        self.learning_rate = learning_rate\n",
    "        self.intercept = intercept\n",
    "        pass\n",
    "\n",
    "\n",
    "      \n",
    "     # Sigmoid Calculation\n",
    "    def sigmoid(self, scores):\n",
    "        return 1 / (1 + np.exp(-scores))\n",
    "\n",
    "\n",
    "    \n",
    "    def log_likelihood(features, target, weights):\n",
    "        scores = np.dot(features, weights)\n",
    "        ll = np.sum( target*scores - np.log(1 + np.exp(scores)) )\n",
    "        return ll\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    # Fit Method of Classifier\n",
    "    def fit(self, X, y):\n",
    "        # data should be as a numpy array\n",
    "        self._data_ = X.copy()\n",
    "        self._targets_ = y.copy()\n",
    "#        self._weights_ = logistic_regression(self._data_, self._targets_, self.step, self.learning_rate, self.intercept)\n",
    "        #If we want to add an intercept \n",
    "        if self.intercept:\n",
    "            intercept = np.ones((self._data_.shape[0], 1))\n",
    "            self._data_ = np.hstack((intercept, self._data_))\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Weight Calculation    \n",
    "        weights = np.zeros(self._data_.shape[1])\n",
    "\n",
    "\n",
    "        for step in range(self.step):\n",
    "            scores = np.dot(self._data_, weights)\n",
    "            predictions = self.sigmoid(scores)\n",
    "\n",
    "            # Update weights with log likelihood gradient\n",
    "            output_error_signal = self._targets_ - predictions\n",
    "\n",
    "            gradient = np.dot(self._data_.T, output_error_signal)\n",
    "            weights += self.learning_rate * gradient\n",
    "            self._weights_ = weights\n",
    "\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    # Predict Method (loop single prediction on sample data points)\n",
    "    def predict(self, sample):\n",
    "        preds=[]\n",
    "        for feats in sample:\n",
    "        \n",
    "            scores = np.dot(feats, self._weights_)\n",
    "            prediction = self.sigmoid(scores)\n",
    "        \n",
    "            if prediction > 0.5:\n",
    "                preds.append(1)\n",
    "            elif prediction <= 0.5:\n",
    "                preds.append(0)\n",
    "        return preds\n",
    "    \n",
    "                \n",
    "    \n",
    "    \n",
    "    # Scoring Function\n",
    "    def score(self, X, y):\n",
    "        y_ = predict(X)\n",
    "        score = 0\n",
    "        for y1, y2 in zip(y, y_):\n",
    "            if y1 != y2:\n",
    "                score += 1\n",
    "        score /= len(y)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Split Data:\n",
    "    def split(xx, test_size):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=test_size)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    # Fit Classifier to data:\n",
    "    def fit(classifier_class, X_train, y_train):\n",
    "        classifier = classifier_class()\n",
    "        classifier.fit(X_train, y_train)\n",
    "        return classifier\n",
    "    \n",
    "    # Classifier Test with Confussion Matrix\n",
    "    def test(classifier, X_test, y_test):\n",
    "        conf_matr = np.zeros((3, 3)) # conf. matrix initiation: predicted, actual\n",
    "        predictions = []\n",
    "        # Fill up conf. matrix:\n",
    "        for sample, target in zip(X_test, y_test):\n",
    "            prediction = classifier.predict([sample])\n",
    "            conf_matr[prediction, target] += 1\n",
    "            predictions.append(prediction)\n",
    "        \n",
    "        # Accuracy :\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        print('Accuracy: ','{0:.4f}%'.format(accuracy * 100))\n",
    "        #conf. matrix:\n",
    "        print('Confussion Matrix:\\n', conf_matr)\n",
    "        \n",
    "    \n",
    "    # Function to run everything\n",
    "    def execution(test_size, classifier_class):\n",
    "        X_train, X_test, y_train, y_test = split(dataset, test_size) # Split data call\n",
    "        classifier = fit(classifier_class, X_train, y_train)  # Fit function call(fit func. fits classifier to data)\n",
    "        test(classifier, X_test, y_test)  # Test function call (conf. matrix and accuracy score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\Programme\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  93.8596%\n",
      "Confussion Matrix:\n",
      " [[37.  3.  0.]\n",
      " [ 4. 70.  0.]\n",
      " [ 0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "    # RUN\n",
    "    execution(0.2, Logistic_Regression_DIY)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   # RUN\n",
    "    execution(0.2, Logistic_Regression_DIY)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
