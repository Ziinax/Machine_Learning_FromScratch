{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# # Import Libraries\n",
    "# =============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# # Data Import\n",
    "# =============================================================================\n",
    "titanic_train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Data cleaning\n",
    "# =============================================================================\n",
    "# Deleting inuseful labels and Dividing into features and Labels\n",
    "titanic_train = titanic_train.drop([ 'name', 'cabin', 'ticket', 'embarked','fare'],axis=1)\n",
    "## Fill Gaps (age)\n",
    "titanic_train.age.fillna(titanic_train.age.dropna().mean(),inplace=True)\n",
    "titanic_train.sex = np.where(titanic_train.sex == 'male', 1, 0)\n",
    "\n",
    "X = titanic_train.values[:, 1:]\n",
    "y = titanic_train.values[:, 0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# # Split Class\n",
    "# =============================================================================\n",
    "\n",
    "# Split - info to use in nodes, represents how the sample is splitted\n",
    "class Split:\n",
    "    # Represents predicat: sample[feat]>=val\n",
    "    def __init__(self, feat, val):\n",
    "        self.feat = feat\n",
    "        self.val = val\n",
    "    # Compare if current object satisfies splitting condition \n",
    "    def match(self, obj):\n",
    "        val = obj[self.feat]\n",
    "        if isinstance(val, int) or isinstance(val, float):\n",
    "            return val >= self.val\n",
    "        else:\n",
    "            return val == self.val\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# # Fucnctions for the decision Tree\n",
    "# =============================================================================\n",
    "# Counts the number of each type of example in a dataset. Returns a dictionary label - count\n",
    "def class_counts(rows):\n",
    "    counts = {} \n",
    "    for row in rows:\n",
    "        label = row[-1]\n",
    "        if label not in counts:\n",
    "            counts[label] = 0\n",
    "        counts[label] += 1\n",
    "    return counts\n",
    "\n",
    "# Partitions a dataset by splitting condition. Returns two sub-datasets, one satisfies condition, one not.\n",
    "def partition(X, split):\n",
    "    X_true, X_false = [], []\n",
    "    for row in X:\n",
    "        if split.match(row):\n",
    "            X_true.append(row)\n",
    "        else:\n",
    "            X_false.append(row)\n",
    "    return X_true, X_false\n",
    "\n",
    "# Calculate the Gini Impurity for a list of rows.\n",
    "def gini(X):\n",
    "    counts = class_counts(X)\n",
    "    impurity = 1\n",
    "    for lbl in counts:\n",
    "        prob_of_lbl = counts[lbl] / float(len(X))\n",
    "        impurity -= prob_of_lbl**2\n",
    "    return impurity\n",
    "\n",
    "# Information Gain\n",
    "def inform_gain(left, right, current_uncertainty):\n",
    "    p = float(len(left)) / (len(left) + len(right))\n",
    "    return current_uncertainty - p * gini(left) - (1 - p) * gini(right)\n",
    "\n",
    "# \"Find the best splitting condition by iterating over every feature / value and calculating the information gain.\n",
    "def find_best_split(X):\n",
    "\n",
    "    best_gain = 0 \n",
    "    best_split = None \n",
    "    current_uncertainty = gini(X)\n",
    "    n_features = len(X[0]) - 1 \n",
    "    for col in range(n_features):\n",
    "        values = set([row[col] for row in X]) \n",
    "        for val in values: \n",
    "            split = Split(col, val)\n",
    "            X_true, X_false = partition(X, split)\n",
    "            if len(X_true) == 0 or len(X_false) == 0:\n",
    "                continue\n",
    "            gain = inform_gain(X_true, X_false, current_uncertainty)\n",
    "            if gain >= best_gain:\n",
    "                best_gain, best_split = gain, split\n",
    "    return best_gain, best_split\n",
    "\n",
    "# Get label with maximal probability in this sample\n",
    "def get_prediction(prediction_dict):\n",
    "    if prediction_dict:\n",
    "        return max(prediction_dict.items(), key=operator.itemgetter(1))[0]\n",
    "    else: return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# # Leaf Class\n",
    "# =============================================================================\n",
    "# A Leaf node classifies data.\n",
    "class Leaf:\n",
    "    def __init__(self, X):\n",
    "        self.predictions = class_counts(X)\n",
    "        \n",
    "# =============================================================================\n",
    "# # Decision Node\n",
    "# =============================================================================  \n",
    "# Node of decision tree. Consists of splitting condition, two childs - true node and false node and current predictions\n",
    "class Decision_Node:\n",
    "   \n",
    "    def __init__(self,\n",
    "                 split,\n",
    "                 true_branch,\n",
    "                 false_branch, X):\n",
    "        self.split = split\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "        self.predictions = class_counts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# # Decision Tree\n",
    "# =============================================================================\n",
    "class decision_tree(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, max_depth = 5):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "        self.pruned_tree = None\n",
    "        \n",
    "#Builds the tree.\n",
    "    def make_tree(self, X):\n",
    "        gain, split = find_best_split(X)\n",
    "        if gain == 0:\n",
    "            return Leaf(X)\n",
    "        X_true, X_false = partition(X, split)\n",
    "        true_branch = self.make_tree(X_true)\n",
    "        false_branch = self.make_tree(X_false)\n",
    "        return Decision_Node(split, true_branch, false_branch, X)\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.tree = self.make_tree(X)\n",
    "        return self\n",
    "\n",
    "    def print_tree(self, node, spacing=\"\", level=0):\n",
    "        if isinstance(node, Leaf):\n",
    "            print(spacing + \"Predict\", node.predictions)\n",
    "            return\n",
    "        if level<self.max_depth:\n",
    "            print(spacing + str(node.split.visualize()))\n",
    "            print(spacing + '--> True:')\n",
    "            self.print_tree(node.true_branch, spacing + \"  \", level+1)\n",
    "            print(spacing + '--> False:')\n",
    "            self.print_tree(node.false_branch, spacing + \"  \", level+1)\n",
    "        else: \n",
    "            print(spacing + \"Predict\", node.predictions)\n",
    "            return\n",
    "\n",
    "# Go through tree\n",
    "    def classify_one(self, row, node, level=0):\n",
    "        if isinstance(node, Leaf):\n",
    "            return node.predictions\n",
    "        while level<self.max_depth:\n",
    "            if node.split.match(row):\n",
    "                return self.classify_one(row, node.true_branch, level+1)\n",
    "            else:\n",
    "                return self.classify_one(row, node.false_branch, level+1)\n",
    "        return node.predictions\n",
    "\n",
    "    def predict(self, X):\n",
    "        pr = []\n",
    "        for row in X:\n",
    "            pr.append(get_prediction(self.classify_one(row, self.tree)))\n",
    "        return pr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "decision_tree(threshold=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# # Fit & Predict\n",
    "# =============================================================================\n",
    "\n",
    "descisionTree = decision_tree()\n",
    "# Fit function call\n",
    "descisionTree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  82.6816%\n",
      "Confussion Matrix:\n",
      " [[105  16]\n",
      " [ 15  43]]\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# # result with my classifier\n",
    "# =============================================================================\n",
    "predictions = descisionTree.predict(X_test)\n",
    "conf_matr = confusion_matrix(y_test, predictions)\n",
    "# Print accuracy and conf. matrix:\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print('Accuracy: ','{0:.4f}%'.format(accuracy * 100))\n",
    "print('Confussion Matrix:\\n', conf_matr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  98.3240%\n",
      "Confussion Matrix:\n",
      " [[102   0]\n",
      " [  3  74]]\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# # Compare with SKLEARN DecisionTreeClassifier:\n",
    "# =============================================================================\n",
    "skDecisionTree = DecisionTreeClassifier()\n",
    "# Fit function call\n",
    "skDecisionTree.fit(X, y)\n",
    "predictions_sk = skDecisionTree.predict(X_test)\n",
    "conf_matr_sk = confusion_matrix(y_test, predictions_sk)\n",
    "# Print accuracy and conf. matrix:\n",
    "accuracy = accuracy_score(y_test, predictions_sk)\n",
    "print('Accuracy: ','{0:.4f}%'.format(accuracy * 100))\n",
    "print('Confussion Matrix:\\n', conf_matr_sk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
